{"path":"P8 - Information/_eps/EP 1.pdf","text":"Engineering Tripos Part IB SECOND YEAR Paper 8 Information Engineering Part B: Image Features and Matching Examples Paper Straightforward questions are marked † Tripos standard (but not necessarily Tripos length) questions are marked ∗ 1. † Images Images are stored as pixel arrays of quantised intensity values. Typically each pixel has a brightness value in the range 0 (black) to 255 (white), and is stored as a single byte (8 bits). Compute the storage requirements (in bytes per second) for a stereo pair of cameras grabbing grey-level images of size 512 × 512 pixels at 25 frames per second. Approximately how many pages of text require the same amount of storage as one second of stereo video? 2. ∗ Smoothing by convolution with a Gaussian A commonly used 1D smoothing ﬁlter is the Gaussian: gσ(x) = 1 σ√ 2π exp ( − x2 2σ2 ) where σ determines the size of the ﬁlter. Show that repeated convolutions with a series of 1D Gaussians, each with a particular standard deviation σi, is equivalent to a single convolution with a Gaussian of variance ∑i σ2 i . 3. Generating the Gaussian ﬁlter kernel A discrete approximation to a 1D Gaussian can be obtained by sampling the function gσ(x). In practice, samples are taken uniformly until the truncated values at the tails of the distribution are less than 1/1000 of the peak value. (a) For σ = 1, show that the ﬁlter obtained in this way has a size of 7 pixels and coeﬃcients given by: 0.004 0.054 0.242 0.399 0.242 0.054 0.004 What property of the coeﬃcients ensures that regions of uniform intensity are unaﬀected by smoothing? (b) Using the same truncation criterion, what would be the size of the discrete ﬁlter kernel for σ = 5? Show that, in general, the size of the kernel can be approximated as 2n + 1 pixels, where n is the nearest integer to 3.7σ − 0.5. (c) The ﬁlter is used to smooth an image as part of an edge detection procedure. What factors aﬀect the choice of an appropriate value for σ? 1 4. † Discrete convolution The following row of pixels is smoothed with the discrete 1D Gaussian kernel given in question 3(a) (σ = 1). Calculate the smoothed value of the pixel with intensity 118. 46 45 45 48 50 53 55 57 77 99 118 130 133 134 133 132 132 132 133 5. Diﬀerentiation and 1D edge detection Show how an approximation to the ﬁrst-order spatial derivative of I(x) can be ob- tained by convolving samples of I(x) with the kernel 1/2 0 -1/2 The smoothed row of pixels in question 4 is shown below. x x x 48 50 53 56 64 79 98 115 126 132 133 133 132 x x x Find the ﬁrst order derivatives and localise the intensity discontinuity. 6. Decomposition of 2D convolution Smoothing a 2D image involves a 2D convolution with a 2D Gaussian: Gσ(x, y) = 1 2πσ2 exp − ( x2 + y2 2σ2 ) Show that this can be performed by two 1D convolutions: i.e. Gσ(x, y) ∗ I(x, y) = gσ(x) ∗ [gσ(y) ∗ I(x, y)] What is the advantage of performing two 1D convolutions instead of a 2D convolu- tion? 7. Correlation and Convolution The correlation of a template g(x, y) (perhaps taken from a diﬀerent image) and the image I(x, y), we may use the cross-correlation which is deﬁned by: c(x, y) = ∫ ∫ I(u + x, v + y)g(u, v)dudv This is usually normalised (by the root-mean-square intensities of each region) so that the cross-correlation will take its maximum value of 1.0 when the 2 signals are identical. Both cross-correlation and convolution involve shifting, multiplication and summa- tion operations. Write down the equation describing the convolution of two signals, I(x, y) and g(x, y). What are the diﬀerences between the cross-correlation and con- volution of two signals? 2 8. ∗ Feature detection and scale space (2018 IB Tripos Paper 8) Consider an algorithm to detect interest points (features of interest) in a 2-D image for use in matching. (a) Show how diﬀerent resolutions of the image can be represented eﬃciently in an image pyramid. Your answer should include details of the implementation of smoothing within an octave and subsampling of the image between octaves. (b) How can band-pass ﬁltering at diﬀerent scales be implemented eﬃciently using the image pyramid? Show how image features such as blob-like shapes can be localized in both position and scale using band-pass ﬁltering. 9. ∗ Feature descriptors (2019/2020 IB Tripos Paper 8) The SIFT (Scale-Invariant Feature Transform) descriptor is used for matching key- points and is computed from a 16 × 16 patch of pixels around each feature. (a) How is the 16 × 16 patch of pixels sampled at an appropriate scale and orienta- tion? (b) Describe the main steps in computing this descriptor. (c) How does it achieve its invariance to lighting, image and viewpoint changes? (d) What are its limitations? 10. ∗ Matching keypoints (2019 IB Tripos Paper 8) In computer vision point correspondences over diﬀerent viewpoints are often used to recover an objects pose (registration) and 3-D shape (reconstruction). Keypoints are ﬁrst detected in each image and then matched to features in the other viewpoints by comparing their descriptors. How are these descriptors used to ﬁnd correspondences in images from diﬀerent viewpoints? 3 Answers 1. 1.3 × 10 7 Bytes/s; ≈ 3000 pages 3. (b) 37 pixels. 4. 115 (to the nearest integer) 5. Between the pixel with intensity 79 and the pixel with intensity 98. More precisely, two-thirds of the way. Suitable past Tripos questions: Q16 on Paper 8 (section F) all exams 2010-2023 Roberto Cipolla April 2024 4","libVersion":"0.2.4","langs":""}