{"path":"P7 - Maths/_handouts/Linalg 1.pdf","text":"1 IB Paper 7: Linear Algebra Handout 1 Jerome Jarrett Aims To introduce the ideas and techniques of Linear Algebra, and illustrate some applications to Engineering. Syllabus • Solution of the matrix equation Ax = b: Gaussian elimination, LU factorization. • Four fundamental subspaces of a matrix. • Least squares solution of Ax = b for an m × n matrix with n independent columns: Solving AT A x = AT b, Gram-Schmidt orthogonalization, QR decomposition. • Solution of Ax = λx, eigenvectors and eigenvalues. • Singular Value Decomposition Text book Gilbert Strang, Linear Algebra and its Applications, Harcourt Brace Jovanich 3rd edition,1988. EC 62 Examples Papers Paper 1 issued today. Paper 2 will be issued . 2 1 Example Application Many problems in engineering involve linear equations. The most recent example you have met is probably in structures, involving a statically indeterminate truss. (a) The equilibrium matrix relates the forces in the members to the applied external forces. Cases like this were analysed in the Structures Course, where A was shown to be: E I II E III IV F V VI F 0 1 010 0 0 0 2 11 00 1 0 0 22 11 0 1 00 0 1 0 0 22 2 10 x y x y ft t f t t f t t Wf ⎡⎤ ⎡⎤ ⎡⎤⎡⎤⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥−− ⎢⎥ ⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥==⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎢⎥− ⎢⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥⎢⎥−− − ⎢⎥ − −⎣⎦ ⎢⎥⎣⎦⎣⎦⎢⎥⎣⎦ The static indeterminacy shows up in the fact that we have 4 equations for 6 unknowns, indicating probably 2 redundant members. (b) The extensions in all of the members must be compatible with the displacements. Written in matrix form, this introduces the compatibility matrix C, de=C A BC D E F V I II III VI IV W x y l l l l E.g. joint E E.g. bar VI 3 which in this case is I E II E III F IV F V VI 01 0 0 00 1 / 2 1 / 2 00 0 1 10 1 0 1/ 2 00 1 / 1/ 2 0 0 21 / 2 x y x y e d e d e d e d e e − ⎡⎤⎡⎤ ⎢⎥⎢⎥ ⎡⎤ ⎢ ⎥⎢⎥− ⎢⎥ ⎢⎥⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥− ⎢⎥ ⎢⎥⎢⎥ = ⎢⎥ ⎢ ⎥⎢⎥− ⎢⎥ ⎢ ⎥⎢⎥ ⎢⎥ ⎢⎥⎢⎥− ⎣⎦ ⎢⎥⎢⎥ ⎢⎥⎢⎥ ⎣⎦ ⎣⎦−− This time we have 6 equations in 4 unknowns. This is an over-specified problem and at least 2 of these equations must be simply linear combinations of 4 others. There can only be 4 independent extensions, and 2 conditions on allowable e’s to make this possible. Coping with the redundancy and the compatibility, especially as the trusses get more complicated, involves considerable physical insight or the linear algebra methods we will develop in this course. A close look at A and C shows that = TCA . (This is no coincidence; it is always the case). When a physical problem involves a matrix A, then TA is usually also involved. The Big Questions Q1 What set of forces can be held in equilibrium with this structure ? i.e. How do we find/describe the set of f, for which there is a solution to A t = f ? We shall call the set of f for which there is a solution, 0t , the Column Space of A . Q2 How can we tell a statically indeterminate case and, when we have one, what is the general solution ? i.e. If we have a solution 0t , is it unique ? If not, the general solution will be 0tt n=+ so what is n ? 0tt n f n=+ = +AA A A so 0n =A We shall call the set of n for which 0n =A the Null Space of A . These correspond, for this application, to sets of bar forces for which there is no applied force. i.e. States of self-stress. Q3 What set of bar extensions are compatible with keeping this structure fitting together ? i.e. How do we find/describe the set of e, for which there is a solution to C d = e ? For consistency with Q1, we should call this the Column Space of C , but since = TCA , we prefer to call it the Row Space of A. 4 Q4 What set of nodal displacements produce zero extensions in the bars ? i.e. How do we find/describe the set of d, for which there is a solution to C d = 0 ? Again for consistency with Q2, we should call this the Null Space of C , but since = TCA , we prefer to call it the Left Null Space of A. 00 0d dd=⇒ = =⇒ T TC AA (taking the transpose). These correspond, for this application, to mechanisms. A similar set of questions tends to crop up in applications of matrix methods to other branches of engineering. The first part of this course, then, is devoted to the general solution of Ax = b, and methods to find the four sets of vectors which answer these four questions. i.e. to find the column space, the null space, the row space and the left-null space of the matrix A. 2 The Geometry of n dimensions Geometrical interpretation is a great help when considering how to solve systems of equations, which in 3 dimensions are planes, lines, etc. In this section, we will try and extend the ideas of lines and planes to dimensions higher than 3. Considered as a mapping, the 4 × 6 matrix A above maps a 6-dimensional vector into a 4- dimensional one I EII EIII IV F V F VI x y x y t ft ft t f t f t ⎡⎤ ⎢⎥ ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥→⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦⎢⎥ ⎢⎥⎣⎦ I E II E III IVF VF VI x y x y e d e d e ed ed e ⎡⎤ ⎢⎥⎡⎤ ⎢⎥⎢⎥ ⎢⎥⎢⎥ → ⎢⎥⎢⎥ ⎢⎥⎢⎥ ⎢⎥⎢⎥⎣⎦ ⎢⎥ ⎢⎥⎣⎦ In general, an m × n matrix A, transforms an n-dimensional vector x into a corresponding m- dimensional vector b. x bA= As we move to dimensions higher than 3, most of the familiar vector properties generalise, and only a few do not. = A b n m n m x 5 4 dimensions (i) We still have 4 independent unit vectors along the “axis” directions 1e = 1 0 0 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ , 2e = 0 1 0 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ , 3e = 0 0 1 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ and 4e = 0 0 0 1 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ (ii) Any vector has 4 components 12 3 412 3 4x x e xe x e xe= ++ + (iii) Length is 2 222 12 3 4x xxxx= +++ (iv) Dot product survives 1 1 22 3 3 44x yx y x y x y x y=+ + +. = Tx y = [ ] 112 3 4 2 3 4 yxx x x y y y ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ We can think of this as defining an angle between two vectors cos x y x y θ = . , and if we do so x ⊥ y ⇔ 0xy =. As in 3-d T2 x xxx x==. (v) All of this is compatible with the corresponding definitions in 3-d, and we still have 11x ex=. 1e . 1e = 1 1e . 2e = 0 , etc. with the angle between 1e and 2e being 90°, etc. (vi) An example of something which doesn’t generalise is cross product x y× . We could try using ˆsinx ynθ , but we come unstuck with ˆn since, in four dimensions, there are two unit vectors perpendicular to x and y . (vii) We can replace 4 by m or n in the above with obvious generalisations. 12 21 nnx xe x e x e=+ + +... The n-dimensional “world” is referred to as Rn. We live in R3 . An m × n matrix A maps Rn to Rm . 6 2.1 The Column Picture for Matrix Multiplication The simplest way of understanding the effect of multiplying by a matrix is to think of the effect on the co-ordinate base vectors. In 3-d, for example, 11 12 13 11 21 22 23 21 31 32 33 31 1 0 0 aa a a ia a a a aa a a ⎡⎤ ⎡ ⎤⎡⎤ ⎢⎥ ⎢ ⎥⎢⎥==⎢⎥ ⎢ ⎥⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥⎣⎦⎣⎦ ⎣ ⎦ A = 1a the first column of A 11 12 13 12 21 22 23 22 31 32 33 32 0 1 0 aa a a ja a a a aa a a ⎡⎤ ⎡ ⎤⎡⎤ ⎢⎥ ⎢ ⎥⎢⎥==⎢⎥ ⎢ ⎥⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥⎣⎦⎣⎦ ⎣ ⎦ A = 2a the second column of A 11 12 13 13 21 22 23 23 31 32 33 33 0 0 1 aa a a ka a a a aa a a ⎡⎤ ⎡ ⎤⎡⎤ ⎢⎥ ⎢ ⎥⎢⎥==⎢⎥ ⎢ ⎥⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥⎣⎦⎣⎦ ⎣ ⎦ A = 3a the third column of A Knowing what happens to the base vectors when we operate on them with A enables us to tell immediately what happens to any vector x. E.g. Simple Shear θ 0 1 0 0 1 0 ⎡⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥→ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ , tan0 1 0 1 0 θ⎡⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥→ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ and 1 0 0 1 0 0 ⎡ ⎤⎡ ⎤ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥→ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥⎣ ⎦⎣ ⎦ ⇒ 1tan 0 01 0 00 1 θ⎡⎤ ⎢⎥ ⎢⎥= ⎢⎥ ⎢⎥⎣⎦ A Then for any vector x, () x xi y j zk x iy j z k =+ + =+ + AA AA A = 12 3x yz++aa a When you multiply a vector by a matrix then, the original co-ordinates multiply the columns of A after the transformation. 7 2.2 The Column Picture for Simultaneous Equations. Let us stay in R3 for the present and consider the problem of solving 3 equations in 3 unknowns. x + 3 y − z = 11 3 x − 2 y − z = 7 − x + y + 4 z = −9 The solution of which can be shown to be x = 3 y = 2 z = −2 This problem can be written in vector form as ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − = ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − − + ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ −+ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − 9 7 11 4 1 1 1 2 3 1 3 1 zyx and the vectors on the left hand side are, as expected, the columns of the matrix A. The problem then is to find which linear combination of the columns on the LHS will give the vector on the RHS. We will refer to this as column visualization or as the column picture. In this case 13 1 11 3 3 22 21 7 11 4 9 −⎡⎤ ⎡ ⎤ ⎡⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥+− − − =⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥−−⎣⎦ ⎣ ⎦ ⎣⎦ ⎣ ⎦ If the vectors which are the columns of A are independent (or rather linearly independent), i.e. you can not express one as a linear combination of the other two, then any vector can be written as a linear combination of them (in a unique way). So the equations are guaranteed to have a (unique) solution for any RHS b. When might the equations not have a solution? If the matrix A is singular, then the columns of A are not independent as is the case for the following set ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − = ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − − − + ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ −+ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − 9 7 11 1 1 1 8 2 3 1 3 1 zyx a1 b a2 a3 x b=A 8 This has the third column lying in the plane spanned by the first two (see below). i.e. 31 2aa aα β=+ . It follows that A anything must also lie in the plane of 12 and aa : ( ) ( ) ()12 3 1 2 1 2 1 2x xa ya za xa ya z a a x z a y z aαβ α β=+ + = + + + = + + +A If b does not also lie in this plane, then there is no solution. If b does lie in this plane, then there is an infinite number of solutions. When we are dealing with 3 × 3 matrices, we know how to determine whether the columns of a matrix are independent and, if so, whether a given vector can be written in terms of them, although the methods we know are laborious. For the matrix referred to above: (i) If we write the equations in the form A x = b, then Determinant A = () ( ) 13 1 32 1 1 2 8 3 3 1 1(24 2) 18 1 − − −= + − − − − − −− 10 12 22 0= +− = This means that A is singular (has no inverse). (ii) The columns of A can not, therefore, be independent. To prove the columns are not independent, we write the third one as a linear combination of the first two. Put 11 3 13 2 11 8 αβ −⎡⎤ ⎡⎤ ⎡ ⎤ ⎢⎥ ⎢⎥ ⎢ ⎥−= + −⎢⎥ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢⎥ ⎢ ⎥−−⎣⎦ ⎣⎦ ⎣ ⎦ . The first two equations give 52 11 11 αβ=− =− (and this also satisfies the third). (iii) Since A x = 12 312 3x ax a x a++ = ( ) ( )13 2 312x xa x x aαβ++ + , for a solution, b must also be a combination of the first two columns of A:- b No solution b ∞ solutions 9 11 1 3 73 2 91 8 γδ ⎡⎤ ⎡ ⎤ ⎡⎤ ⎢⎥ ⎢ ⎥ ⎢⎥=+ −⎢⎥ ⎢ ⎥ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢⎥−−⎣⎦ ⎣ ⎦ ⎣⎦ Use the first two components to find γ andδ ⇒ 43 26 11 11 γδ== ⇒ third component of b must be 15 for a solution to exist. 2.3 Vector Spaces and Subspaces of Rn. We would like to hang onto these pictures, even though we will move into n and m dimensional space. For a general non-square m × n matrix A x = ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ mnmm n n a...aa ............ a...aa a...aa 21 22221 11211 1 2 ... n x x x ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ = 12 312 3 ... n nx ax a x a x a+ ++ + where the ai are the column vectors of A . As the xi vary, they sweep out the part of Rm that we can get to by multiplying a vector in Rn by A . For our equilibrium matrix in the problem described in section 1 I II III IV V VI 000 1 1 2 0 10 0 0 1 2 0 01 2 0 1 0 1 2 01 2 1 0 0 1 2 t t t t t t ⎡ ⎤ ⎢ ⎥⎡⎤− ⎢ ⎥⎢⎥ ⎢ ⎥−−⎢⎥ ⎢ ⎥⎢⎥ − ⎢ ⎥⎢⎥ ⎢ ⎥⎢⎥ −− −⎣⎦⎢ ⎥ ⎢ ⎥⎣ ⎦ = I II III IV V VI 0000 1 1 2 0010 0 12 01 2 0 1 1 20 01 012 0 1 2 tt t t t t ⎡⎤ ⎡⎤ ⎡ ⎤−⎡⎤ ⎡ ⎤ ⎡⎤ ⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥ ⎢ ⎥ ⎢⎥− −⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥ ⎢ ⎥ ⎢⎥++ + + +⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥ ⎢ ⎥ ⎢⎥ − ⎢⎥ ⎢⎥ ⎢ ⎥⎢⎥ ⎢ ⎥ ⎢⎥ −⎢⎥ ⎢⎥ ⎢ ⎥−−⎣⎦ ⎣ ⎦ ⎣⎦⎣⎦ ⎣⎦ ⎣ ⎦ The region mapped out in Rm as the xi vary (e.g. that in R4 as the ti vary) is called a vector space and it is a straightforward generalisation to arbitrary dimensions of the concept of a line or a plane. The formal definition is A vector space in Rm is the set of x of the form xu v wλ μν=+ + + ... where u, v, ... are fixed m-vectors and λ, μ, ... are variable scalars taking all real values. The vectors u, v, ... are said to span the space. This must be changed to 15 for a solution to exist. 10 Rm is itself a vector space and “smaller” ones within it are said to be sub-spaces of Rm. For example: The non-trivial sub-spaces of R3 are (a) x λu= lines through the origin (b) x λuvμ= + planes through the origin. (c) x λuv wμ ν=+ + = whole of R3 2.4 How many dimensions ? We would naturally describe a line as a one-dimensional sub-space of R3 and a plane as a two- dimensional subspace since within these spaces we have one and two “degrees of freedom”. The term “dimension” is thus used in two senses – number of degrees of freedom and number of co- ordinates. Every point on a line has 3 co-ordinates and is thus a three-dimensional vector but the line is a one-dimensional object. This ambiguity does not, in general, cause confusion. In drawing the diagrams above, we have assumed that the vectors u, v and w are independent. For case (d), if u, v, w are not independent (i.e. one of them can be written as a sum of the other two), we can drop it from the list of vectors necessary to span the space. If wu vα β=+ ⇒ ( ) ( )x λ uvναμ νβ=+ + + ⇒ x uvλ μ′′= + and we only have a plane. Similarly considerations apply for (b) and (c). A set of vectors u, v, ... which span the space and are also independent are said to form a basis and the number of these is the dimension of the sub-space. The basis of a vector sub-space is not unique – any full set of independent vectors will do, but it will always contain the same number of vectors. 0 u v 0 u v 0 u w 11 e.g. The sub-spaces of R3 which are given by 10 11 01 x λμ ⎡⎤ ⎡⎤ ⎢⎥ ⎢⎥=+⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦ ⎣⎦ 11 10 01 x λμ ⎡⎤⎡ ⎤ ⎢⎥⎢ ⎥′′=+⎢⎥⎢ ⎥ ⎢⎥⎢ ⎥−⎣⎦⎣ ⎦ 13 1 12 2 01 1 x λμ ν ⎡⎤⎡ ⎤ ⎡ ⎤ ⎢⎥⎢ ⎥ ⎢ ⎥′′′′ ′′=+ +⎢⎥⎢ ⎥ ⎢ ⎥ ⎢⎥⎢ ⎥ ⎢ ⎥−⎣⎦⎣ ⎦ ⎣ ⎦ turn out to be the same and, moreover, these are not the only way of representing the plane. Whatever vectors are used, however, it needs two and only two independent vectors to describe it. Sets of Independent Vectors (typical properties) 1) Complete the following, for vectors in R3 : Two vectors are linearly dependent if they lie on the same line (through the origin) Three vectors are linearly dependent if they lie in the same plane (through the origin) Four vectors are certain to be linearly dependent. 2) What is the maximum number of vector in an independent set in R6 ? 6 3) The mathematical test for linear independence is: The vectors xi , i = 1, ..., n are linearly independent if, whenever 02211 =+++ nn x...xx λλλ for any scalars λi , i = 1, ..., n , then we must have 12 ... 0nλ λλ= == = (If one of the λ's is non-zero, then we can solve this equation for the vector it multiplies in terms of the others). 4) Show that if xi , i = 1, ..., n are a basis for the vector space S, then every vector in S has a unique representation in terms of them. x ∈ S ⇒ 1212 ... n nsx x xλ λλ=+ + + . If also 1212 ... n nsx x xμ μμ=+ + + then subtracting gives () ( ) ( )11 2 2120 ... nn nx xxλμ λ μ λ μ=− + − + + − ⇒ 11 2 20 λ μλ μ= −= − etc 2.5 Column Space The vector space spanned by the columns of a general m × n matrix A is called the column space of A. The dimension (in the degrees of freedom sense) of column space is called the rank of A. So, for example, if A is a 3 × 3 matrix If rank(A) = 3 column space = whole of R3 If rank(A) = 2 column space = a plane. (We lose 1 dimension in the mapping) If rank(A) = 1 column space = a line (We lose 2 dimensions in the mapping) If rank(A) = 0 column space = 0 (We lose 3 dimensions in the mapping). If we lose dimensions, then we can not reverse a mapping. If A is n × n , then if it loses dimensions, rank(A) < n, it is singular. If it doesn’t, rank(A) = n, then its inverse will exist. 12 Now for a general m × n matrix because A x = ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ mnmm n n a...aa ............ a...aa a...aa 21 22221 11211 1 2 ... n x x x ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ = 12 312 3 ... n nx ax a x a x a+ ++ + the following should be fairly clear. (i) Column space is part of Rm and so the number of independent columns of A can not exceed m, i.e. rank(A) ≤ m. In addition, there are only n columns, so rank(A) ≤ n. The 4 × 6 equilibrium matrix studied earlier can not, therefore, have more than 4 independent columns. (ii) If b lies in column space, then Ax = b has at least one solution. (iii) If b is not in column space, then Ax = b has no solution. (iv) If rank(A) = m, so that column space = whole of Rm, then b must lie in column space. Key Points from Lecture • In general, an m × n matrix A, transforms an n-dimensional vector x into a corresponding m- dimensional vector b. x b=A • The n-dimensional “world” is Rn. An m × n matrix A maps Rn to Rm. A x = 11 12 1 21 22 2 12 ... ... ... ... ... ... ... n n mm mn aa a aa a aa a ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ 1 2 ... n x x x ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ = 12 312 3 ... n nx ax a x a x a+ ++ + where the ai are the column vectors of A . • As the xi vary, they sweep out the part of Rm that we can get to by multiplying a vector in Rn by A . This is Column Space which is a vector sub-space of Rm (i.e a generalisation of a line or a plane) • The dimension of Column Space = number of independent columns of A is called the rank(A) ≤ smaller of m and n. A (far from unique) set of independent vectors which span the column space of A, i.e. a basis, will contain rank(A) vectors. You can now do Examples Paper 1 Questions 1 - 3 = A b n m n m x","libVersion":"0.2.4","langs":""}