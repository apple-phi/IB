{"path":"IB7-LA-2h.pdf","text":"1 IB Paper 7: Linear Algebra Handout 2 2.6 The Column Picture for Matrix Multiplication, revisited We saw in Handout 1 that when we multiply a matrix and a vector, we get A x = 11 12 1 21 22 2 12 ... ... ... ... ... ... ... n n mm mn aa a aa a aa a ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ 1 2 ... n x x x ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ = 12 ... ... naa a ⎡ ⎤↑ ↑↑ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓⎣ ⎦ 1 2 ... n x x x ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ = 11 2 2 3 3 ... nnx ax a x a x a++ + + In this section we will show that something similar happens when we multiply two matrices together. Consider the simplest case of the product of two simple matrices a b e f ae bg af bh ae af bg bh c d g h ce dg cf gh ce cf dg dh ++⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ == = = +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥++⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ABC acef g h bd ⎡ ⎤⎡ ⎤⎡⎤ ⎡ ⎤⎣ ⎦⎣ ⎦=+⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ A This pattern generalises 11 12 13 11 12 13 21 22 23 21 22 23 31 32 33 31 32 33 bb b c c c bb b c c c bb b c c c ⎡⎤ ⎡⎤ ⎢⎥ ⎢⎥== ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦ ⎣⎦ ABC 11 11 12 21 13 31 11 12 12 22 13 32 11 13 12 23 13 33 21 11 22 21 23 31 21 12 22 22 23 32 21 13 22 23 23 33 31 11 32 21 33 31 31 12 32 22 33 32 31 13 32 23 33 33 bc b c b c bc b c b c bc b c b c b c bc b c b c bc b c b c bc b c b c b c bc b c b c bc b c b c bc ++ + + + +⎡ ⎤ ⎢ ⎥ ⎢ ⎥=+ + + + + + ⎢ ⎥ ⎢ ⎥++ + + + +⎣ ⎦ Splitting into 3 matrices 11 11 11 12 11 13 12 21 12 22 12 23 13 31 13 32 13 33 21 11 21 12 21 13 22 21 22 22 22 33 23 31 23 32 23 33 31 11 31 12 31 13 32 21 32 22 32 23 33 31 33 32 33 33 b c b c b c b c b c b c bc bc bc b c b c b c bc bc bc b c b c b c b c b c b c b c b c b c bc bc bc ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥=+ + ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢⎣⎦ ⎣ ⎦ ⎣ ⎦⎥ Now, these matrices can be recognised as [ ] [ ] [ ]11 11 12 13 12 21 22 23 13 31 32 33 21 22 23 31 32 33 bc c c b c c c b c c c bb b bb b ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥=+ + ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ ⎣ ⎦ A 2 If we denote the columns of B as b1, b2, etc. and the rows of C as 1c% , 2c% , etc. then this can be written more succinctly as TT T 11 2 2 3 3bc b c b c=+ +A %% % A product of vectors x yT is referred to as an outer product of x and y . (the dot product xT y = x . y is also called an inner product). So that A = BC = sum of the outer products of each of the columns of B with the corresponding row of C. This is not the only consequence of viewing the product like this. If we denote the columns of A as a1, a2, etc. [ ] [ ] [ ]11 12 13 21 22 23 31 32 33 12 3 1 2 3 cc c c c c c c c aa a b b b ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ↑ ↑ ↑ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ =+ +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓ ↓ ↓ ↓⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ is equivalent to [ ] [ ] [ ]11 21 31 11 2 3 cc c ab b b ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ↑ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ =+ +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓ ↓⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ [ ] [] [ ]12 22 32 21 2 3 cc c ab b b ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ↑ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ =+ +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓ ↓⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ and [ ] [ ] [ ]13 23 33 31 2 3 cc c ab b b ⎡⎤ ⎡ ⎤ ⎡⎤ ⎡ ⎤↑↑ ↑ ↑ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ =+ +⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥↓↓ ↓ ↓⎣⎦ ⎣ ⎦ ⎣⎦ ⎣ ⎦ Now, there is nothing special about 3 × 3 matrices. For the general case of A = B C where A is an m × n matrix, B is an m × k matrix, C is an k × n matrix, [ ] [ ] [] 11 12 1 21 22 2 12 1 2 12 nn n kk kn k cc c c c c aa a b b cc c b ⎡⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ↑ ↑ ⎢⎥ ⎢ ⎥ ⎢ ⎥ =+ +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓ ↓ ↓⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎡⎤↑ ⎢⎥ + ⎢⎥ ⎢⎥↓⎣⎦ ... ... ... ... ... ... ... (2.1) 3 or more succinctly TT T T 11 2 2 3 3 kkbc b c b c b c=+ + + +A ...%% % % (2.2) This is a really powerful relationship. It enables us to move back and forth between matrix multiplication and relationships between sets of vectors. For the j’th column of A 12 12 j jkj jk cc c ab b b ⎡⎤ ⎡ ⎤ ⎡ ⎤⎡⎤ ⎡⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ↑⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ =+ + +⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓↓ ⎣⎦ ⎣ ⎦ ⎣ ⎦⎣⎦ ... So, for example, [ ] [ ]37 0 1 2 1 1 2 1 211 2 1 4 1 05 3 1 1 1 4 1 1 1 − − −⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ == +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥−− − −⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ is equivalent to 31 2 11 01 1 ⎡⎤ ⎡ ⎤ ⎡ ⎤ =+⎢⎥ ⎢ ⎥ ⎢ ⎥−⎣⎦ ⎣ ⎦ ⎣ ⎦ () 71 2 51 1 14 ⎡⎤ ⎡ ⎤ ⎡⎤ =+⎢⎥ ⎢ ⎥ ⎢⎥−⎣⎦ ⎣ − ⎣ ⎦⎦ () 01 2 31 1 21 ⎡⎤ ⎡ ⎤ ⎡ ⎤ =+⎢⎥ ⎢ ⎥ ⎢ ⎥−−⎣⎣ ⎦ ⎣ ⎦ − ⎦ Note that we have started to write the scalars multiplying the vectors after them. In the current framework, we are thinking of scalars as 1 × 1 matrices and they have to go behind since, when n > 1, you can multiply a (n × 1) matrix times a (1 × 1) but not a (1 × 1) times a (n × 1) . Examples We can also use this to find matrices that manipulate column vectors. (a) Find the matrix which swaps the 2nd and 3rd columns of a 3 × 3 matrix. If we write this as A = B C, then, in terms of the columns of A and B, this is equivalent to 11ab= 23ab= 32ab= i.e. 12 3aa a ⎡⎤↑↑ ↑ ⎢⎥ ⎢⎥ ⎢⎥↓↓ ↓⎣⎦ = [ ] [ ] 12 3 10 0 0 1000 1 bb b ⎡⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥++ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎡⎤⎣⎦ = 12 3bb b ⎡⎤↑↑ ↑ ⎢⎥ ⎢⎥ ⎢⎥↓↓ ↓⎣⎦ 10 0 001 01 0 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ C is a permutation matrix, that shuffles the rows. Note that its columns are mutually orthogonal unit vectors, i.e. it is an orthogonal matrix meaning that its inverse is its transpose. 4 (b) Find the matrix which subtracts 1 × first column and 2 × second column from the 3rd, while leaving the first and second columns alone. In terms of column vectors 11ab= 22ba= 33 1 22ab b b= −− 12 3aa a ⎡⎤↑↑ ↑ ⎢⎥ ⎢⎥ ⎢⎥↓↓ ↓⎣⎦ = [ ] [ ] [ ] 12 3 10 1 0 1 2 0 0 1 bb b ⎡⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥++ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓⎣⎦ ⎣ − ⎦⎣ ⎦ − = 213bb b ⎡⎤↑↑ ↑ ⎢⎥ ⎢⎥ ⎢⎥↓↓ ↓⎣⎦ 10 1 01 2 00 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ − − 2.7 The Row Picture for Matrix Multiplication It is usually true for matrices that, if there is a property that applies to columns, then there is a corresponding one that applies to rows. Returning to (2.1) & (2.2) for the general case A = B C where A is an m × n matrix, B is an m × k matrix, C is an k × n matrix, we see that TT T T 11 2 2 3 3 kkbc b c b c b c=+ + + +A ...%% % % can also be interpreted as 11 12 11 12 21 22 22 12 k k k mm mkm a bb bcc c a bb b a bb b ←→⎡⎤ ⎡⎤ ⎡ ⎤ ⎡ ⎤←→ ← → ←→⎡⎤⎡⎤ ⎡ ⎤⎣⎦ ⎣ ⎦ ⎣⎦ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥←→⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥=+ + + ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ←→ ⎣⎦ ⎣ ⎦ ⎣ ⎦⎣⎦ ... ... ... ... ... ... ... % %% % % % i.e. [ ] [ ] [ ]11 12 111 2 k kab c b c b c←→ = ← → + ← → + + ← →⎡⎤⎡⎤ ⎡ ⎤ ⎡ ⎤⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣⎦...%% % % [ ] [ ] [ ]21 22 221 2 k kab c b c b c←→ = ← → + ← → + + ← →⎡⎤⎡⎤ ⎡ ⎤ ⎡ ⎤⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣⎦...%% % % ………………………………………………… [ ] [ ] [ ]1212mm mkm kab c b c b c←→ = ← → + ← → + + ← →⎡⎤ ⎡ ⎤⎡⎤ ⎡ ⎤⎣⎦ ⎣ ⎦⎣⎦ ⎣ ⎦...%% % % where the notation 1c% has been used to indicate that we are talking about vectors which represent the rows, rather than the columns. The general form for the i’th row is [ ] [ ] [ ]1212ii iki kab c b c b c←→ = ← → + ← → + + ← →⎡⎤ ⎡ ⎤⎡⎤ ⎡ ⎤⎣⎦ ⎣ ⎦⎣⎦ ⎣ ⎦...%% % % 5 So, for example, [ ] [ ]37 0 1 2 1 1 2 1 211 2 1 4 1 05 3 1 1 1 4 1 1 1 − − −⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ == +⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥−− − −⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ ⎣ ⎦ is equivalent to []37 0 11 1 2 2 1 4 1⎡⎤= ⎡ ⎤ ⎣⎦ ⎣⎦− +− and []05 3 11 1 2 11 4 1⎡⎤ ⎡⎤ ⎣ = ⎦⎦ − ⎣−− + − Examples (a) Find the matrix which subtracts 1 × first row and 2 × second row from the 3rd, while leaving the first and second rows alone. In terms of row vectors 11ac=%% 22ac=%% 33 1 22ac c c= −−%% % % ⇒ 1 2 3 a a a ←→⎡⎤ ⎢⎥ ←→⎢⎥ ⎢⎥←→⎣⎦ % % % = 10 0 01 0 12 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦−− 1 2 3 c c c ← →⎡ ⎤ ⎢ ⎥ ← →⎢ ⎥ ⎢ ⎥← →⎣ ⎦ % % % (b) Find the matrix which cyclically permutes the rows of a 4 × 4 matrix (i.e. 1 → 2, 2 → 3, 3 → 4, 4 → 1 ** 21cb= ** 32cb= ⇒ 1 2 3 4 a a a a ←→⎡⎤ ⎢⎥←→⎢⎥ ⎢⎥←→ ⎢⎥ ←→⎣⎦ % % % % = 000 1 10 0 0 01 0 0 001 0 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ 1 2 3 4 c c c c ←→⎡⎤ ⎢⎥←→⎢⎥ ⎢⎥←→ ⎢⎥ ←→⎣⎦ % % % % But hang on a minute Because addition of matrices can be done in any order, the relationship TT T T TT 1 1 2 2 33 33 1 1 2 2b c b c bc bc b c b c=+ + = + +A %% % % %% appears to suggest that we can re-arrange the columns of B provided we apply the same re- arrangement to the rows of C. This is in fact true. If the permutation matrix to rearrange the columns of B is P (as a post-multiplier), then the permutation matrix for the rows of C is P T (as a pre-multiplier). ()() ( ) TT Tand== = =ABC BP P C B PP C PP I 6 3. LU Factorisation This technique is inspired by traditional ( = Gaussian elimination) methods for solving simultaneous equations. The idea is that we factorise an m × n matrix A into the form A = LU where L is lower-triangular m × m matrix with 1's down the leading diagonal and U is an upper- echelon matrix which is the same shape as A. Lower triangular means that L has non-zero terms only on and below the leading diagonal (e.g 4 × 4) 10 0 0 *1 0 0 ** 1 0 ** * 1 ⎡⎤ ⎢⎥ ⎢⎥= ⎢⎥ ⎢⎥ ⎣⎦ L where * represents a possibly non-zero value. Upper echelon means that all non-zero elements are on or above the leading diagonal. e.g. (3 × 4) ** * * 0* * * 00 * * ⎡⎤ ⎢⎥= ⎢⎥ ⎢⎥⎣⎦ U where * represents a possibly non-zero value. If A is square, then so is U and then U is said to be upper triangular. The technique is best demonstrated by examples. We are seeking to write TT T T 11 2 2 3 3 mmlu l u l u l u== + + + +A LU ...%% % % and l1, l2 , … are the columns of L and 1u% , 2u% , … are the rows of U. These rows and columns can be generated in turn because of the particular patterns of 1's and 0's. 21 2 64 3 43 0 21 2 00 012 1 2 01 336 3 6 01 424 2 4 ⎡⎤⎡⎤−⎡⎤ ⎢⎥⎢⎥ +⎢⎥ ⎢⎥⎢⎥⎢⎥−= ⎢⎥⎢⎥⎢⎥ ⎢⎥⎢⎥⎢⎥⎣⎦ ⎣⎦⎣⎦ − − − − T 11 restlu +A % We have chosen 1u% to be the first row of A and l1 is determined by 1 as the first component and then whatever is necessary to make the first column of T 11lu% equal to the first column of A. These choices give us a zero top row and a zero first column in the matrix representing \"the rest\". i.e. T 11lu=−Rest A % We now repeat the exercise with the “rest” to choose l2 and 2u% 7 00 1 000 000 0 01 3 01 3 0 01 4 01 3 013 00 0 0 10 0 0 10 01 1 ⎡⎤ ⎡ ⎤⎡ ⎤ ⎢⎥ ⎢ ⎥⎢ ⎥+ ⎢⎥ ⎢ ⎥⎢ ⎥= ⎢⎥ ⎢ ⎥⎢ ⎥ ⎢⎥ ⎢ ⎥⎢ ⎥ ⎣⎦ ⎣ ⎦⎣ ⎦ TT 22 3 3 rest = lu l u+Rest %% and, in general, repeat. In this case we can, however, spot l3 and 3u% immediately. Note that, after each stage of the process, \"rest\" has one more zero row and one more zero column. Gathering results 12 1 2 0 0 1 2 0 0 0 1 310 21 1 ⎡⎤⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤⎣⎦ ⎣ ⎦ ⎣ ⎦⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥=+ + ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ ⎣⎦⎣⎦ − − A = 10 0 103 21 1 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦ 21 2 10 1 3 00 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦ − = L U 3.2 A Second Example This time I have already inserted the numbers which are determined by the chosen 1's and 0's in L and U. 12 0 11 3 37 5 12 0 12 0 1311 2 0 0001 0 1533 0 06 ⎡⎤⎡⎤⎡⎤ ⎢⎥⎢⎥ +⎢⎥ ⎢⎥⎢⎥⎢⎥−− = ⎢⎥⎢⎥⎢⎥ ⎢⎥⎢⎥⎢⎥⎣⎦ ⎣⎦⎣⎦ −− − T 11 restlu +A % 00 0 00 0 0 00 0 0 10 0 0 0 0 01 0 0 13 2 13 11 3 2 ⎡ ⎤⎡ ⎤ ⎢ ⎥⎢ ⎥+ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎣ ⎦⎣ ⎦ 8 A = 10 0 11 0 131 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ − 12 0 130 00 2 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ 3.3 Non-square matrices A = 12 1 3 26 3 12 12 2 8 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥−⎣⎦ No Problem. 12 1 3 26 3 12 12 2 8 12 1 3 12 1 3 21 62 242 6 43 1111 000 01 0 21 3 0 ⎡ ⎤⎡⎤⎡⎤ ⎢ ⎥⎢⎥+⎢⎥ ⎢ ⎥⎢⎥⎢⎥ = ⎢ ⎥⎢⎥⎢⎥ ⎢ ⎥⎢⎥⎢⎥−⎣⎦ ⎣ ⎦⎣⎦−− − − − 00 021 6 1 00 0 0 0 0 0 0 0 0 1 1 21 6 24 2 12 0 0 000 0 01 1100 ⎡⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥+ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎣⎦ ⎣ ⎦ − − ⇒ A = 10 0 102 112 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦− 12 1 3 21 6 100 1 0 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦− 3.4 A first look at the solution of Ax = b Consider the equations 2 x + y − 2 z = 1 6 x + 4 y − 3 z = 5 4 x + 3 y = 5 We have already performed LU decomposition on A and we shall see how the simple forms for L and U pay off when we try to solve these equations. 21 2 64 3 43 0 −⎡ ⎤ ⎢ ⎥ ⎢ ⎥⇒= − ⎢ ⎥ ⎢ ⎥⎣ ⎦ A 1 5 5 ⎡⎤ ⎢⎥ ⎢⎥= ⎢⎥ ⎢⎥⎣⎦ b 9 A = LU where L = 10 0 31 0 21 1 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ U = 21 2 01 3 00 1 ⎡ ⎤− ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ The solution method then is simply ( ) ( )x xx b== =ALU L U We solve this in two steps, (i) find c from Lc = b and then (ii)find x from Ux = c . i.e. Lc = b 1 2 3 10 0 1 31 0 5 21 1 5 c c c ⎡⎤⎡⎤ ⎡ ⎤ ⎢⎥⎢⎥ ⎢ ⎥⇒=⎢⎥⎢⎥ ⎢ ⎥ ⎢⎥⎢⎥ ⎢ ⎥⎣⎦ ⎣ ⎦⎣⎦ Solve by forward substitution (i.e. solve the first equation, substitute into the second, etc.) 12 1 3 1 215 3 2 5 2 1cc c c c c== − = = − − = Then Ux = c 21 2 1 01 3 2 00 1 1 x y z ⎡⎤− ⎡⎤⎡ ⎤ ⎢⎥⎢⎥⎢ ⎥⇒=⎢⎥⎢⎥⎢ ⎥ ⎢⎥⎢⎥⎢ ⎥⎣⎦⎣ ⎦⎣⎦ Solve by backward substitution (i.e. solve the last equation, substitute into the second last, etc.) () 11 2 3 1 122 2 zy z x y z== − = − = − + = A bit of jargon: The first non-zero elements of U in each row are called pivots. The pivot for x is 2, the pivot for y is 1, that for z is 1. At any stage in the back substitution: pivot × unknown = known. The terms below the diagonal of L are multipliers. 3 and 2 are the multipliers for x. 1 is the multiplier for y. We shall discuss in a later section that large pivots and the small multipliers keeps the problem well-conditioned. We will extend the LU decomposition to ensure that this happens. You can now do Examples Paper 1 Questions 4 and 5 21 2 1 0 0 01 3 3 10 00 1 2 11 −⎡⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥==⎢⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ UL 10 Key Points from Lecture • A = B C ( A m × n B m × k C k × n ) is equivalent to TT T T 11 2 2 3 3 kkbc b c b c b c=+ + + +A ...%% % % which is a sum of outer products. • This is a relationship between the columns of A and the columns of B with the elements of C as the coefficients. 12 12 j jkj jk cc c ab b b ⎡⎤ ⎡ ⎤ ⎡ ⎤⎡⎤ ⎡⎤ ⎡ ⎤ ⎡ ⎤↑↑ ↑ ↑⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ =+ + +⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥↓↓ ↓↓ ⎣⎦ ⎣ ⎦ ⎣ ⎦⎣⎦ ... • In addition, it also represents a relationship between the rows of A and the rows of C with the elements of B representing the coefficients. [ ] [ ] [ ]1212ii iki kab c b c b c←→ = ← → + ← → + + ← →⎡⎤ ⎡ ⎤⎡⎤ ⎡ ⎤⎣⎦ ⎣ ⎦⎣⎦ ⎣ ⎦...%% % % LU Factorisation L U A = 12 1 3 26 3 12 12 2 8 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥−⎣⎦ = 10 0 21 0 12 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥−⎣ ⎦ 12 1 3 02 1 6 00 1 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥−⎣ ⎦ L is always a square matrix, while U always has the same shape as A. Solution of Ax = b Recast this as (i) find c from Lc = b and then (ii)find x from Ux = c .","libVersion":"0.2.4","langs":""}