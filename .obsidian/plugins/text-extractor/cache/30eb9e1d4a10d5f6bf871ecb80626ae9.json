{"path":"P7 - Maths/_handouts/Linalg 3.pdf","text":"1 IB Paper 7: Linear Algebra Handout 3 3.5 Making LU decomposition robust – Partial Pivoting When we say an algorithm is robust, we mean that it should be able to obtain an accurate solution for the majority of cases without user intervention i.e. it should not be easily \"fooled\" or get \"hung up\" by particular combinations of data. This raises the question what might go wrong with the algorithm we have used so far. It helps to look at that algorithm in a bit more detail, exemplified initially using 3 × 3 matrices. Step 1 Choose [] T 1u abc=% and 1 1 ld e ⎡ ⎤ ⎢ ⎥= ⎢ ⎥ ⎢ ⎥⎣ ⎦ so that T 1 11 00 0 0 0 lu r s tu ⎡ ⎤ ⎢ ⎥=− = ⎢ ⎥ ⎢ ⎥⎣ ⎦ RA % ⇒ [ ] 1 1 abc a b c dda db dc eea eb ec ⎡⎤⎡ ⎤ ⎢⎥⎢ ⎥=− = −⎢⎥⎢ ⎥ ⎢⎥⎢ ⎥⎣⎦⎣ ⎦ RA A It is clear that 1u% must be the first row of A, and that 21a d a = and 31a e a = Step 2 Choose [] T 2 0ug h=% and 2 0 1l f ⎡ ⎤ ⎢ ⎥= ⎢ ⎥ ⎢ ⎥⎣ ⎦ so that TT T 21 22 1 1 22 00 0 00 0 00 lu l u lu w ⎡ ⎤ ⎢ ⎥=− = − − = ⎢ ⎥ ⎢ ⎥⎣ ⎦ RR A%% % ⇒ [ ] 21 00 0 0 0 0 0 0 10 0 00 gh rs g h f t u fg fh ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎢⎥ ⎢ ⎥ ⎢ ⎥=− = −⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ ⎣ ⎦ RR so that 2u% is the second row of R1 and t f g = After each step of the process the remainder matrix has one more row and one more column of zeros, and the process continues until we run out of rows. This gives us the potential problem about what to do if g (or its equivalent element in a later stage of the process when A is bigger than 3 × 3) turns out to be 0 . If you look back at the end of the previous handout, you will see that the 2 thing we divide by at each step is called the pivot element for this step. This symptom is, therefore, often referred to as a zero candidate pivot element. If we were doing this by hand, we would know what to do as the next example illustrates, we would choose a different pivot. Example Perform LU on 21 2 63 3 43 0 −⎡⎤ ⎢⎥−⎢⎥ ⎢⎥⎣⎦ Step 1 21 2 21 2 1 2 1 2 0 0 0 63 3 3 6 3 6 0 0 3 43 0 2 4 2 4 0 1 4 − −−⎡⎤ ⎡ ⎤ ⎡ ⎤ +⎢⎥ ⎢ ⎥ ⎢ ⎥−= −⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥−⎣⎦ ⎣ ⎦ ⎣ ⎦ Step 2 01 4 000 0 0 00 000 00 3 0 000 0 03 01 4 1 01 4 0 0 0 ⎡⎤ ⎡ ⎤ ⎡ ⎤ +⎢⎥ ⎢ ⎥ ⎢ ⎥=⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎢ ⎥⎣⎦ ⎣ ⎦ ⎣ ⎦ Note that we have still zeroed one additional row and one column in this step, so the decomposition is still on track. Step 3 00 3 000 0 000 003 1 003 000 0 000 ⎡⎤⎡ ⎤ ⎢⎥⎢ ⎥=⎢⎥⎢ ⎥ ⎢⎥⎢ ⎥⎣⎦⎣ ⎦ Pulling this together [ ] [ ] [ ]1 2 1 2 00 1 4 00 0 3 30 1 21 0 ⎡⎤ − ⎡⎤ ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥=+ +⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦ ⎣⎦⎣⎦ A = 10 0 301 21 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ ⎥ ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎢ ⎣ ⎡ − 300 410 212 = ˆLU Note that ˆL isn't quite lower triangular but, in the immortal words of the MATLAB help file, ˆL is \"psychologically equivalent\" to a lower triangular matrix. 3 We can tidy this up a bit if we now permute the rows of ˆL to get it into triangular form ⇒ 10 0 21 0 30 1 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ = 10 0 00 1 01 0 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ 10 0 301 21 0 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ L P T ˆL Please forgive this notation. It is designed so that we end up with something snappy. Now, a permutation matrix has rows and columns which are orthogonal unit vectors, so it is an orthogonal matrix which means that its inverse is its transpose. We have now an extended LU decomposition of the form Tˆ==ALU P LU ⇒ =PA LU where P is a permutation matrix. Computer algorithms will ensure that there are a minimum of difficulties of this type during the factorisation process by, at every stage, scanning the remaining non-zero elements in the next column in the remainder matrix to be zeroed and choosing the largest (in absolute value). This technique is called partial pivoting . (Full pivoting would involve scanning all of the remaining non-zero elements and choosing to use the largest one as the tool for zeroing whatever column it happened to be in). It is a matter of personal preference whether one thinks of deriving a \"psychologically equivalent\" lower triangular matrix, as we did above, or whether one swaps rows of A whenever this type of problem occurs to use the original LU with a modified matrix A which has permuted rows. As long as you keep track of what is being permuted where, then it makes no difference. MATLAB and/or OCTAVE do it this way by default. [ ] L , U, P lu(A)= Example Use partial pivoting on the matrix .6 2.04 .2 .3 .62 1.06 3.2 0 ⎡⎤ ⎢⎥ ⎢⎥= ⎢⎥ ⎢⎥⎣⎦ A The largest pivot element in the first column is 3. 4 Step 1 3.2 0 02 .2.2 .6 .04 0 0.6 1.06.1 .3 02 0 00 013 .2 0 .6 2.04 .2 .3 .62 1.06 3.2 0 ⎡⎤⎡⎤ ⎡ ⎤⎢⎥⎢⎥ ⎢ ⎥+ ⎢⎥⎢⎥ ⎢ ⎥= ⎢⎥⎢⎥ ⎢ ⎥⎢⎥⎢⎥ ⎢ ⎥⎣⎦⎣⎦ ⎣ ⎦ Step 2 02 .2 0 0 1 10 2 .2 0 0 0 0 .3 0.6.06 1 0 0 1 00 0 0 0 0 0 0 ⎡ ⎤⎡ ⎤ ⎢ ⎥⎢ ⎥+ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎢ ⎥⎢ ⎥ ⎣ ⎦⎣ ⎦ For this step we have used 2 as the largest potential pivot. In matrix form A = .2 1 0 .1 .3 1 10 0 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ 3.2 0 02 .2 00 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥⎣ ⎦ Permute the rows, ⇒ .2 1 0 .1 .3 1 10 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ = 01 0 001 100 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ 10 0 .2 1 0 .1 .3 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ giving 00 1 10 0 01 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ .6 2.04 .2 .3 .62 1.06 3.2 0 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥⎣⎦ = 10 0 .2 1 0 .1 .3 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ 3.2 0 02 .2 00 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ A further consequence of this way of choosing the pivot element is that all of the pivot elements have ended up large and all of the multipliers are less than unity. L = 10 0 .2 1 0 .1 .3 1 ⎡⎤ ⎢⎥ ⎢⎥ ⎢⎥ ⎣⎦ U = 3.2 0 02 .2 00 1 ⎡ ⎤ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎣ ⎦ The L and U that we have ended up with have their largest terms on the diagonal (and so will be well conditioned when it comes to forward and backward substitution). This is a good thing, as the following example shows. 5 3.6 Ill-conditioned problems The examples presented in this section are somewhat extreme, so that we can see the principles on small (2 × 2 matrices). The general m × n case shows exactly the same features/problems but with less extreme data. Suppose .0001 2 2.0001 11 2 x xb y ⎡ ⎤⎡ ⎤ ⎡ ⎤ ==⎢ ⎥⎢ ⎥ ⎢ ⎥ ⎣ ⎦⎣ ⎦ ⎣ ⎦ A Performing non-intelligent basic LU decomposition leads us to ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ 11 20001. = ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ 110 01 4 ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ −199990 20001. We re-write Ax = b as LUx = b and solve Ux = c, where Lc = b 1 4 2 10 2.0001 210 1 c cb c ⎡⎤⎡⎤⎡⎤ == =⎢⎥⎢⎥⎢⎥ ⎢⎥ ⎣⎦⎣⎦⎣⎦ L Solving this by forward substitution 1 4 21 2.0001 2 10 2 20001 19999 c cc = =− =− = − Then Ux = c is solved by backward substitution ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ − =⎥ ⎦ ⎤ ⎢ ⎣ ⎡ ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ − 19999 00012 199990 20001 . y x. This gives () 100011020001210 1 44 =×=−= = .y.x y which is correct Now this is all well and good if we are working to exact precision. Machines, however, will always be working to a limited number of significant figures. If, for example, y was in error by 1 part in 10−6, y = 1.000001, then this last equation becomes () 4410 2.0001 2 10 .000098 .98xy=− = × = (*) i.e. we don't even have three significant figure accuracy for x, which is not exactly robust. The trouble comes from the fact that the pivot for x , .0001, is very small, and so any errors on the right-hand side of (*) are immediately multiplied by a large number (104). This equation is said to be ill-conditioned. For the extended LU method, it is clear that the permutation matrix will simply swap the rows, so then we can proceed naively. This time we solve PAx = Pb . (NOT Ax = b ) 6 0 1 .0001 2 0 1 2.0001 10 1 1 10 2 x y ⎡⎤ ⎡ ⎤ ⎡ ⎤ ⎡⎤ ⎡ ⎤ =⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎢⎥ ⎢ ⎥ ⎣⎦ ⎣ ⎦ ⎣ ⎦ ⎣⎦ ⎣ ⎦ i.e. 11 2 .0001 2 2.0001 x y ⎡ ⎤⎡ ⎤ ⎡ ⎤ =⎢ ⎥⎢ ⎥ ⎢ ⎥ ⎣ ⎦⎣ ⎦ ⎣ ⎦ LU decomposition gives 11 .0001 2 ⎡ ⎤ ⎢ ⎥ ⎣ ⎦ = 4 10 10 1 − ⎡ ⎤ ⎢ ⎥ ⎢ ⎥⎣ ⎦ 11 0 1.9999 ⎡ ⎤ ⎢ ⎥ ⎣ ⎦ 1 4 2 10 2 2.000110 1 c cb c− ⎡⎤⎡⎤⎡ ⎤ =⇒ =⎢⎥⎢⎥⎢ ⎥ ⎢⎥ ⎣ ⎦⎣⎦⎣⎦ LP Solving this by forward substitution 1 4 21 2 2.0001 10 2.0001 0.0002 1.9999 c cc − = =− =− = Then Ux = c is solved by backward substitution 11 2 0 1.9999 1.9999 x y ⎡⎤ ⎡ ⎤ ⎡ ⎤ =⎢⎥ ⎢ ⎥ ⎢ ⎥ ⎣⎦ ⎣ ⎦ ⎣ ⎦ This gives 1 21 y xy = =− = Any error in y then gives a comparable error in x. Final Note LU in its partial-pivoting mode is immune to introducing ill-conditioning into a problem. But it should be noted that some problems are ill-conditioned (as opposed the algorithm used to solve them being ill-conditioned). All algorithms (including LU) will stuggle with ill-conditioned problems. e.g. 12 2 4.0001 ⎡⎤ = ⎢⎥ ⎣⎦ A 2 4.0001 ⎡⎤ = ⎢⎥ ⎢⎥⎣⎦ Ax ⇒ x = 0, y = 1 2 4 ⎡⎤ = ⎢⎥ ⎢⎥⎣⎦ Ax ⇒ x = 2, y = 0 You can see that det A = .0001 which is four orders of magnitude less than a typical element. The matrix A is \"nearly singular\". When faced with a problem like this it usually means that you have set the problem up the wrong way. Key Point from Lecture LU decomposition with partial pivoting is PA = LU You can now do Ex Paper 1 Q 6 & 7","libVersion":"0.2.4","langs":""}